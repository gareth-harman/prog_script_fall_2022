{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI565: Bioinformatics Programming & Scripting\n",
    "\n",
    "#### (C) Michael Mooney (mooneymi@ohsu.edu)\n",
    "\n",
    "## Week 4: XML, HTML and Web Scraping\n",
    "\n",
    "*** Thanks to Ryan Swan for the materials on HTML and web scraping.**\n",
    "\n",
    "1. XML Overview\n",
    "    - XML Format\n",
    "2. The Python ElementTree Class\n",
    "    - Reading XML\n",
    "    - Writing XML\n",
    "3. XML and Bioinformatics\n",
    "1. HTML\n",
    "    * Organization of HTML files\n",
    "2. LXML Package\n",
    "    * HTML as a tree structure\n",
    "    * XPath queries\n",
    "    * Element objects\n",
    "    * HTML tag attributes\n",
    "3. Beautiful Soup\n",
    "    * Soup objects and methods\n",
    "    * Using tag attributes with BeautifulSoup\n",
    "4. The Web Developers Console\n",
    "5. A note about APIs and `robots.txt`\n",
    "\n",
    "\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "- Python 2.7 or 3.5\n",
    "- `xml.etree.ElementTree` module\n",
    "- `lxml` module\n",
    "- `requests` module\n",
    "- `BeautifulSoup (beautifulsoup4)` module\n",
    "- `io` module\n",
    "- Data Files\n",
    "    - `./data/book.xml`\n",
    "    - `./data/SHH.xml`\n",
    "- Miscellaneous Files\n",
    "    - `./images/book_tree.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML Overview\n",
    "\n",
    "<b>XML</b> stands for E<u>x</u>tensible <u>M</u>arkup <u>L</u>anguage, and is a set of rules for encoding documents in a machine-readable format. In bioinformatics, XML is a commonly used format for sharing heterogenous data (as opposed to delimited files, where every record (row) contains the same data elements).\n",
    "\n",
    "The World Wide Web Consortium (W3C) oversaw XML development in 1996.\n",
    "\n",
    "#### XML Design Goals:\n",
    "1. XML shall be straightforwardly usable over the Internet\n",
    "2. XML shall support a wide variety of applications\n",
    "3. XML shall be compatible with Standard Generalized Markup Language (SGML)\n",
    "4. It shall be easy to write programs that process XML documents\n",
    "5. The number of optional features in XML is to be kept to the absolute minimum\n",
    "6. XML documents should be human-legible and reasonably clear\n",
    "7. The XML design should be prepared quickly\n",
    "8. The design of XML shall be formal and concise\n",
    "9. XML documents shall be easy to create\n",
    "10. Terseness in XML markup is of minimal importance\n",
    "\n",
    "#### Why can't we use CSV formats?\n",
    "1. We usually can, but...\n",
    "1. CSV files are not always human readable (other documentation is often necessary to identify data elements)\n",
    "2. Inconsistencies are more likely \n",
    "3. CSV files don't easily support multiple levels of data\n",
    "4. CSV files don't easily support addition details such as formatting or meta data (experimental protocols, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UniProt Example: Sonic Hedgehog Protein\n",
    "\n",
    "[http://www.uniprot.org/uniprot/Q15465.xml](http://www.uniprot.org/uniprot/Q15465.xml)\n",
    "\n",
    "I've provided this file in the course materials, saved as `SHH.xml`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML Format\n",
    "\n",
    "The first couple lines of an XML document contain information about the XML version used, the document structure and comments:\n",
    "\n",
    "#### Version\n",
    "    <?xml version='1.0' encoding='UTF-8'?>\n",
    "    \n",
    "#### Document Type Declaration\n",
    "    <uniprot xmlns=\"http://uniprot.org/uniprot\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://uniprot.org/uniprot http://www.uniprot.org/support/docs/uniprot.xsd\">\n",
    "\n",
    "#### XML Document Body\n",
    "\n",
    "The body of an XML document contains labeled data elements. Data elements can be nested to show relationships. Data labels are called \"tags\", which can also contain attributes (values are always strings) that provide additional information about the data.\n",
    "    \n",
    "    <parent_tag>\n",
    "        <child_tag attribute1=\"value1\" attrubute2=\"value2\">data</child_tag>\n",
    "    </parent_tag>\n",
    "\n",
    "It is subjective whether to provide additional information as attributes or additional data elements:\n",
    "\n",
    "    <contact birthdate=\"1-1-1980\">\n",
    "        <name>John Smith</name>\n",
    "    </contact>\n",
    "    \n",
    "    <contact>\n",
    "        <name>John Smith</name>\n",
    "        <birthdate>1-1-1980</birthdate>\n",
    "    </contact>\n",
    "\n",
    "#### DTD and XML Schema\n",
    "\n",
    "- Document Type Definitions (DTD) and XML Schemas are two ways of describing the structure and content of an XML document\n",
    "- XML Schemas (a.k.a. XML Schema Definitions or XSDs) were designed to improve upon the shortcomings of DTDs\n",
    "    - data type support\n",
    "    - namespace aware\n",
    "- Example: the UniProt XSD - [http://www.uniprot.org/support/docs/uniprot.xsd](http://www.uniprot.org/support/docs/uniprot.xsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElementTree\n",
    "### Reading XML\n",
    "\n",
    "There are two strategies for reading an XML document:\n",
    "\n",
    "1. Document Object Model\n",
    "    - Read the entire file, analyze relationships between elements, and build a tree structure which can be navigated/searched\n",
    "    - Uses the innate organization of the data\n",
    "    - Examples: `minidom`, `elementtree`, `lxml` Python modules\n",
    "2. Event Driven Parsers (SAX or Simple API for XML)\n",
    "    - Read the XML file and report events, such as the start and end of an element\n",
    "    - Uses less memory, no tree construction\n",
    "    - Examples: `sax` and `elementtree` Python modules\n",
    "    \n",
    "We will be covering both the `elementtree` and `lxml` modules in this lecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Simple Example\n",
    "\n",
    "    <book>\n",
    "        <title>Nineteen Eighty‚ÄêFour</title>\n",
    "        <author>George Orwell</author>\n",
    "        <character>Winston Smith</character>\n",
    "        <character>Julia</character>\n",
    "    </book>\n",
    "\n",
    "    import xml.etree.ElementTree as et\n",
    "    tree = et.parse(\"1984.xml\")\n",
    "\n",
    "In the example above, `tree` is an ElementTree object containing a tree of the entire XML file. ElementTree objects are iterable objects. We can iterate through these object to access individual elements. Start by accessing the root of the tree. Each element object contains three main attributes: the tag name `tag`, the text inside the tag `text`, and the tag attributes `attrib`.\n",
    "\n",
    "    root_element = tree.getroot()\n",
    "    for element in root_element:\n",
    "        print element.tag\n",
    "        print element.text\n",
    "        print element.attrib\n",
    "\n",
    "<img src=\"./images/book_tree.jpg\" align=\"left\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another Example: `book.xml`\n",
    "\n",
    "    <book>\n",
    "\t<title>Ender's Game</title>\n",
    "\t<author>Orson Scott Card</author>\n",
    "\t<chapter>Third</chapter>\n",
    "\t<chapter>Peter</chapter>\n",
    "\t<chapter>Graff</chapter>\n",
    "    <publication_info>\n",
    "\t\t<publisher location=\"New York\">Tor Books</publisher>\n",
    "\t\t<publication_date>1985</publication_date>\n",
    "\t</publication_info>\n",
    "    </book>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'book' at 0x104278bf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "tree = et.parse('./data/book.xml')\n",
    "root_element = tree.getroot()\n",
    "root_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'title' at 0x104281dd0>,\n",
       " <Element 'author' at 0x104291890>,\n",
       " <Element 'chapter' at 0x1042918f0>,\n",
       " <Element 'chapter' at 0x104291950>,\n",
       " <Element 'chapter' at 0x1042919b0>,\n",
       " <Element 'publication_info' at 0x104291a10>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(root_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: Ender's Game\n",
      "author: Orson Scott Card\n",
      "chapter: Third\n",
      "chapter: Peter\n",
      "chapter: Graff\n",
      "publication_info: \n"
     ]
    }
   ],
   "source": [
    "for element in root_element:\n",
    "    print(element.tag + \":\", element.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'publication_info' at 0x104291a10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_element[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root_element[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'publisher' at 0x104291ad0>,\n",
       " <Element 'publication_date' at 0x104291b30>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(root_element[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: Ender's Game ,  {}\n",
      "author: Orson Scott Card ,  {}\n",
      "chapter: Third ,  {}\n",
      "chapter: Peter ,  {}\n",
      "chapter: Graff ,  {}\n",
      "publication_info:  ,  {}\n",
      "\tpublisher: Tor Books ,  {'location': 'New York'}\n",
      "\tpublication_date: 1985 ,  {}\n"
     ]
    }
   ],
   "source": [
    "## Each element is iterable, which allows access\n",
    "## to child elements. Here we check the length of\n",
    "## each element to get the number of children\n",
    "for element in root_element:\n",
    "    if len(element) > 0:\n",
    "        print(element.tag + \":\", element.text.strip(), \", \", element.attrib)\n",
    "        for child in element:\n",
    "            print(\"\\t\" + child.tag + \":\", child.text.strip(), \", \", child.attrib)\n",
    "    else:\n",
    "        print(element.tag + \":\", element.text.strip(), \", \", element.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElementTree Element Methods\n",
    "\n",
    "<table align=\"left\">\n",
    "<tr><td style=\"text-align:center\"><b>Method</b></td><td><b>Description</b></td></tr>\n",
    "<tr><td style=\"text-align:center\">`Element.iter(tag=None)`</td><td>Creates a tree iterator with the current element as root.<br />If `tag` is specified, only those elements with a tag equal to `tag` are returned by the iterator.</td></tr>\n",
    "<tr><td style=\"text-align:center\">`Element.find(tag)`</td><td>Returns the first subelement with a tag equal to `tag` or `None` if no match.</td></tr>\n",
    "<tr><td style=\"text-align:center\">`Element.findall(tag)`</td><td>Returns a list of all matching subelements.</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Orson Scott Card'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = root_element.find(\"author\")\n",
    "author.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Third', 'Peter', 'Graff']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters = root_element.findall(\"chapter\")\n",
    "[c.text for c in chapters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the XML file is very large, you may want to use an iterator, rather than creating a tree of the entire file all at once. The `iterparse()` method implements an event-driven parser. It will return an iterator of (event, element) tuples, where event indicates the part of an element encountered (e.g. the start tag or end tag). By default, only end events are returned. Since, `iterparse()` still creates a tree in memory, you can use the `Element.clear()` method to save memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n",
      "title: Ender's Game\n",
      "end\n",
      "author: Orson Scott Card\n",
      "end\n",
      "chapter: Third\n",
      "end\n",
      "chapter: Peter\n",
      "end\n",
      "chapter: Graff\n",
      "end\n",
      "publisher: Tor Books\n",
      "end\n",
      "publication_date: 1985\n",
      "end\n",
      "publication_info: \n",
      "end\n",
      "book: \n"
     ]
    }
   ],
   "source": [
    "iter_et = et.iterparse('./data/book.xml')\n",
    "for event, element in iter_et:\n",
    "    print(event)\n",
    "    print(element.tag + \":\", element.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: Ender's Game\n",
      "author: Orson Scott Card\n",
      "chapter: Third\n",
      "chapter: Peter\n",
      "chapter: Graff\n",
      "publisher: Tor Books\n",
      "publication_date: 1985\n",
      "publication_info: \n"
     ]
    }
   ],
   "source": [
    "## Use clear() to clear each element after processing\n",
    "## including the root element\n",
    "iter_et = et.iterparse('./data/book.xml', events=['start', 'end'])\n",
    "event, root = next(iter_et)\n",
    "for event, element in iter_et:\n",
    "    if event == \"end\" and element.tag != root.tag:\n",
    "        print(element.tag + \":\", element.text.strip())\n",
    "        element.clear()\n",
    "\n",
    "root.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XML Namespaces\n",
    "\n",
    "XML namespaces are used to create uniquely named elements and attributes in an XML document. Since a single document may contain element names from multiple vocabularies, ambiguity can arise from the same element name used for different entity definitions. The namespace is appended to the front of tag names to create unique names. In the UniProt example shown above, the attribute `xmlns=\"http://uniprot.org/uniprot\"` specifies the UniProt namespace (in the document type declaration.\n",
    "\n",
    "A document's namespace can be extracted from the root element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{http://uniprot.org/uniprot}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the XML document's namespace\n",
    "import re\n",
    "shh_tree = et.parse('./data/SHH.xml')\n",
    "shh_root = shh_tree.getroot()\n",
    "namespace = re.match(r\"{.*}\", shh_root.tag).group()\n",
    "namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SHH_HUMAN'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Append the namespace to any element name\n",
    "## you want to find\n",
    "entry = shh_root.find(namespace+'entry')\n",
    "entry.find(namespace+'name').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SHH_HUMAN'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = {'uniprot':'http://uniprot.org/uniprot'}\n",
    "entry = shh_root.find('uniprot:entry', ns)\n",
    "entry.find(\"uniprot:name\", ns).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element '{http://uniprot.org/uniprot}entry' at 0x10431a770>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry = shh_root.find('{http://uniprot.org/uniprot}entry')\n",
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry2 = shh_root.find('entry')\n",
    "entry2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing XML\n",
    "\n",
    "#### Methods for Writing XML\n",
    "<table align=\"left\">\n",
    "<tr><td style=\"text-align:center\"><b>Method</b></td><td><b>Description</b></td></tr>\n",
    "<tr><td style=\"text-align:center\">`et.Element(tag)`</td><td>Creates an element with the specified tag. Returns an element object.</td></tr>\n",
    "<tr><td style=\"text-align:center\">`et.SubElement(element, tag)`</td><td>Creates a child element under the specified element.</td></tr>\n",
    "<tr><td style=\"text-align:center\">`Element.set(key, value)`</td><td>Sets the attributes of an element.</td></tr>\n",
    "<tr><td style=\"text-align:center\">`et.ElementTree(root)`</td><td>Returns an ElementTree object.</td></tr>\n",
    "<tr><td style=\"text-align:center\">`ElementTree.write(file)`</td><td>Writes an ElementTree object to a file.</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a simple XML file\n",
    "root = et.Element(\"book\")\n",
    "title = et.SubElement(root, \"title\")\n",
    "title.text = \"Nineteen Eighty-Four\"\n",
    "author = et.SubElement(root, \"author\")\n",
    "author.text = \"George Orwell\"\n",
    "\n",
    "\n",
    "tree.write(\"1984.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<book><title>Nineteen Eighty-Four</title><author>George Orwell</author><publication_info><publisher location=\"London\">Secker and Warburg</publisher></publication_info></book>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('1984.xml') as fh:\n",
    "    data = fh.read()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawbacks to XML?\n",
    "\n",
    "- More difficult to parse than CSV\n",
    "- Verbose syntax means larger files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML and Bioinformatics\n",
    "#### SBML (Systems Biology Markup Language)\n",
    "- Used to communicate models of biological processes (cell-signaling pathways, regulatory networks). Models can represent:\n",
    "    - Chemical Equations\n",
    "    - Cellular Components: nucleus, cytoplasm, etc.\n",
    "    - Species: genomes, proteomes, etc.\n",
    "- Supported by many applications: [http://sbml.org/SBML_Software_Guide](http://sbml.org/SBML_Software_Guide)\n",
    "- [http://www.ebi.ac.uk/biomodels-main/](http://www.ebi.ac.uk/biomodels-main/)\n",
    "\n",
    "#### KGML (KEGG Markup Language)\n",
    "- A format for KEGG pathway maps\n",
    "    - [http://www.kegg.jp/kegg/xml/](http://www.kegg.jp/kegg/xml/)\n",
    "    \n",
    "#### PDBML (Protein Databank Markup Language)\n",
    "- Describes 3D protein structure\n",
    "    - relative atomic coordinates\n",
    "    - secondary structure assignment\n",
    "    - atomic connectivity\n",
    "- [http://www.rcsb.org/pdb/home/home.do](http://www.rcsb.org/pdb/home/home.do)\n",
    "- [http://pdbml.pdb.org/](http://pdbml.pdb.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML\n",
    "\n",
    "Hypertext Markup Language (HTML) is the basis for most pages that are served on the internet. HTML is actually very similar to XML (Extensible Markup Language), with the caveat that it also contains presentation semantics, which are attributes that specify how information is meant to be displayed or arranged on a screen. But overall, the nested format is almost exactly like an XML document, and because of that, we can extract information from a standard HTML page exactly the same way we would from an XML document. Below is a simple example of an HTML document:\n",
    "\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Hey look, a webpage!</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>webpage goes here</p>\n",
    "    </body>\n",
    "    </html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LXML package\n",
    "\n",
    "The LXML package for Python contains methods to read HTML pages like a tree structure. It uses a querying syntax called XML Path Language (XPath) to parse the tree structure and return relevent information from the document.\n",
    "\n",
    "Before we get started, it helps to have an idea of some of the ways that HTML arranges documents. Most scrapable HTML data is contained in tables like the one at http://www.bioinformatics.org/sms/iupac.html. HTML tables are arranged in the following format:\n",
    "\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            ...\n",
    "        </tr>\n",
    "        <tr>\n",
    "            ...\n",
    "        </tr>\n",
    "    </table>\n",
    "\n",
    "This general format specifies table rows and table dividers, where each divider is a different column. The data in the table is contained inside each of the nested <td></td> tag pairs. \n",
    "\n",
    "XPath querying allows us to find specific kinds of elements and their contents. Let's use the tables on the following webpage as an example: [http://www.bioinformatics.org/sms/iupac.html](http://www.bioinformatics.org/sms/iupac.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import requests\n",
    "from io import StringIO # This will help us deal with string inputs\n",
    "\n",
    "## Get the code from the url\n",
    "html = requests.get(\"http://www.bioinformatics.org/sms/iupac.html\").text\n",
    "\n",
    "## Next we have to create a parser that will read the info from the HTML \n",
    "## file and tell it what kind of data it will be receiving\n",
    "parser = etree.HTMLParser()\n",
    "tree = etree.parse(StringIO(html),parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the webpage represented as a tree of data. This tree is an iterable object, just like we saw above when working with XML documents. We can do all sorts of things now.\n",
    "\n",
    "For example with can iterate through the tree with a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element head at 0x10511c690>\n",
      "\t<Element meta at 0x10511c7d0>\n",
      "\t<Element meta at 0x10511c820>\n",
      "\t<Element meta at 0x10511c870>\n",
      "\t<Element title at 0x10511c7d0>\n",
      "<Element body at 0x10511c6e0>\n",
      "\t<Element table at 0x10511c9b0>\n",
      "\t<Element br at 0x10511ca00>\n",
      "\t<Element table at 0x10511c7d0>\n"
     ]
    }
   ],
   "source": [
    "## Note: here we are only showing two levels of the tree\n",
    "root = tree.getroot()\n",
    "\n",
    "for e in root:\n",
    "    print(e)\n",
    "    for i in e:\n",
    "        print('\\t' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Element head at 0x10511df00>\n",
      "\t\t<Element meta at 0x10511e050>\n",
      "\t\t<Element meta at 0x10511e0a0>\n",
      "\t\t<Element meta at 0x10511e0f0>\n",
      "\t\t<Element title at 0x10511e050>\n",
      "\t<Element body at 0x10511c6e0>\n",
      "\t\t<Element table at 0x10511e050>\n",
      "\t\t\t<Element tr at 0x10511e230>\n",
      "\t\t\t\t<Element td at 0x10511e370>\n",
      "\t\t\t\t\t<Element font at 0x10511e4b0>\n",
      "\t\t\t\t<Element td at 0x10511e3c0>\n",
      "\t\t\t\t\t<Element font at 0x10511e410>\n",
      "\t\t\t<Element tr at 0x10511e280>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x10511e370>\n",
      "\t\t\t<Element tr at 0x10511e3c0>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x10511e5a0>\n",
      "\t\t\t<Element tr at 0x10511e370>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x10511e690>\n",
      "\t\t\t<Element tr at 0x10511e5a0>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x10511e780>\n",
      "\t\t\t<Element tr at 0x10511e690>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x10511e870>\n",
      "\t\t\t<Element tr at 0x10511e780>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x10511e960>\n",
      "\t\t\t<Element tr at 0x10511e870>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x10511ea50>\n",
      "\t\t\t<Element tr at 0x10511e960>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x10511eb90>\n",
      "\t\t\t<Element tr at 0x10511ea50>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x10511ec80>\n",
      "\t\t\t<Element tr at 0x10511eb90>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x10511ed70>\n",
      "\t\t\t<Element tr at 0x10511ec80>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x10511ee60>\n",
      "\t\t\t<Element tr at 0x10511ed70>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x10511ef50>\n",
      "\t\t\t<Element tr at 0x10511ee60>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x1051250a0>\n",
      "\t\t\t<Element tr at 0x10511ef50>\n",
      "\t\t\t\t<Element td at 0x10511e410>\n",
      "\t\t\t\t<Element td at 0x1051250a0>\n",
      "\t\t\t<Element tr at 0x10511c640>\n",
      "\t\t\t\t<Element td at 0x1051250a0>\n",
      "\t\t\t\t<Element td at 0x105125230>\n",
      "\t\t\t<Element tr at 0x10511ee60>\n",
      "\t\t\t\t<Element td at 0x105125230>\n",
      "\t\t\t\t<Element td at 0x1051250a0>\n",
      "\t\t<Element br at 0x10511e0f0>\n",
      "\t\t<Element table at 0x10511c7d0>\n",
      "\t\t\t<Element tr at 0x10511e050>\n",
      "\t\t\t\t<Element td at 0x105125230>\n",
      "\t\t\t\t\t<Element font at 0x1051254b0>\n",
      "\t\t\t\t<Element td at 0x1051253c0>\n",
      "\t\t\t\t\t<Element font at 0x105125550>\n",
      "\t\t\t\t<Element td at 0x1051254b0>\n",
      "\t\t\t\t\t<Element font at 0x105125690>\n",
      "\t\t\t<Element tr at 0x10511e0a0>\n",
      "\t\t\t\t<Element td at 0x105125780>\n",
      "\t\t\t\t<Element td at 0x1051257d0>\n",
      "\t\t\t\t<Element td at 0x105125910>\n",
      "\t\t\t<Element tr at 0x10511c640>\n",
      "\t\t\t\t<Element td at 0x105125b40>\n",
      "\t\t\t\t<Element td at 0x105125b90>\n",
      "\t\t\t\t<Element td at 0x10511caa0>\n",
      "\t\t\t<Element tr at 0x105125910>\n",
      "\t\t\t\t<Element td at 0x103a44960>\n",
      "\t\t\t\t<Element td at 0x1043079b0>\n",
      "\t\t\t\t<Element td at 0x104ffc140>\n",
      "\t\t\t<Element tr at 0x10511caa0>\n",
      "\t\t\t\t<Element td at 0x105125d70>\n",
      "\t\t\t\t<Element td at 0x105125dc0>\n",
      "\t\t\t\t<Element td at 0x105125f00>\n",
      "\t\t\t<Element tr at 0x104ffc140>\n",
      "\t\t\t\t<Element td at 0x10512b190>\n",
      "\t\t\t\t<Element td at 0x10512b1e0>\n",
      "\t\t\t\t<Element td at 0x10512b320>\n",
      "\t\t\t<Element tr at 0x105125f00>\n",
      "\t\t\t\t<Element td at 0x10512b550>\n",
      "\t\t\t\t<Element td at 0x10512b5a0>\n",
      "\t\t\t\t<Element td at 0x10512b6e0>\n",
      "\t\t\t<Element tr at 0x10512b320>\n",
      "\t\t\t\t<Element td at 0x10512b910>\n",
      "\t\t\t\t<Element td at 0x10512b960>\n",
      "\t\t\t\t<Element td at 0x10512baa0>\n",
      "\t\t\t<Element tr at 0x10512b6e0>\n",
      "\t\t\t\t<Element td at 0x10512bcd0>\n",
      "\t\t\t\t<Element td at 0x10512bd20>\n",
      "\t\t\t\t<Element td at 0x10512be60>\n",
      "\t\t\t<Element tr at 0x10512baa0>\n",
      "\t\t\t\t<Element td at 0x10512e0f0>\n",
      "\t\t\t\t<Element td at 0x10512e140>\n",
      "\t\t\t\t<Element td at 0x10512e280>\n",
      "\t\t\t<Element tr at 0x10512be60>\n",
      "\t\t\t\t<Element td at 0x10512e4b0>\n",
      "\t\t\t\t<Element td at 0x10512e500>\n",
      "\t\t\t\t<Element td at 0x10512e640>\n",
      "\t\t\t<Element tr at 0x10512e280>\n",
      "\t\t\t\t<Element td at 0x10512e870>\n",
      "\t\t\t\t<Element td at 0x10512e8c0>\n",
      "\t\t\t\t<Element td at 0x10512ea00>\n",
      "\t\t\t<Element tr at 0x10512e640>\n",
      "\t\t\t\t<Element td at 0x10512ec30>\n",
      "\t\t\t\t<Element td at 0x10512ec80>\n",
      "\t\t\t\t<Element td at 0x10512edc0>\n",
      "\t\t\t<Element tr at 0x10512ea00>\n",
      "\t\t\t\t<Element td at 0x105131050>\n",
      "\t\t\t\t<Element td at 0x1051310a0>\n",
      "\t\t\t\t<Element td at 0x1051311e0>\n",
      "\t\t\t<Element tr at 0x10512edc0>\n",
      "\t\t\t\t<Element td at 0x105131410>\n",
      "\t\t\t\t<Element td at 0x105131460>\n",
      "\t\t\t\t<Element td at 0x1051315a0>\n",
      "\t\t\t<Element tr at 0x10512efa0>\n",
      "\t\t\t\t<Element td at 0x1051317d0>\n",
      "\t\t\t\t<Element td at 0x105131820>\n",
      "\t\t\t\t<Element td at 0x105131960>\n",
      "\t\t\t<Element tr at 0x1051315a0>\n",
      "\t\t\t\t<Element td at 0x105131b90>\n",
      "\t\t\t\t<Element td at 0x105131be0>\n",
      "\t\t\t\t<Element td at 0x105131d20>\n",
      "\t\t\t<Element tr at 0x105131960>\n",
      "\t\t\t\t<Element td at 0x105131f50>\n",
      "\t\t\t\t<Element td at 0x105131fa0>\n",
      "\t\t\t\t<Element td at 0x105134140>\n",
      "\t\t\t<Element tr at 0x105131d20>\n",
      "\t\t\t\t<Element td at 0x105134320>\n",
      "\t\t\t\t<Element td at 0x105134370>\n",
      "\t\t\t\t<Element td at 0x1051344b0>\n",
      "\t\t\t<Element tr at 0x105131f00>\n",
      "\t\t\t\t<Element td at 0x1051346e0>\n",
      "\t\t\t\t<Element td at 0x105134730>\n",
      "\t\t\t\t<Element td at 0x105134870>\n",
      "\t\t\t<Element tr at 0x1051344b0>\n",
      "\t\t\t\t<Element td at 0x105134a50>\n",
      "\t\t\t\t<Element td at 0x105134aa0>\n",
      "\t\t\t\t<Element td at 0x105134be0>\n"
     ]
    }
   ],
   "source": [
    "## The following function will print the entire tree structure\n",
    "## This function looks in each element node, and if it has \n",
    "## contents it performs the same action on the descendent node\n",
    "## Note that this is an example of recursion - a function \n",
    "## that calls itself.\n",
    "\n",
    "def parseTree(e,t='\\t'):\n",
    "    for i in e:\n",
    "        print(str(t) + str(i))\n",
    "        parseTree(i,t=t + '\\t')\n",
    "\n",
    "parseTree(tree.getroot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `etree` object has a method called `xpath()`, which allows us to perform queries on the tree structure to identify specific elements within the HTML document. For example, if we want to find all tables within the body of the document we would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element table at 0x104315410>, <Element table at 0x10511c7d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This will return a list of table elements\n",
    "tables = tree.xpath('body/table')\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use tag attributes to perform more specific queries. For instance, we know that the table containing amino acid codes has three columns. To extract this table we could do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element table at 0x10511c7d0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This will find all tables with three columns\n",
    "## Note: the // means it will look anywhere under the current element (root in this case) \n",
    "## (i.e. the table could be nested within another element)\n",
    "amino = tree.xpath(\"//table[@cols='3']\")\n",
    "amino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "A\n",
      "Ala\n",
      "Alanine\n",
      "C\n",
      "Cys\n",
      "Cysteine\n",
      "D\n",
      "Asp\n",
      "Aspartic Acid\n",
      "E\n",
      "Glu\n",
      "Glutamic Acid\n",
      "F\n",
      "Phe\n",
      "Phenylalanine\n",
      "G\n",
      "Gly\n",
      "Glycine\n",
      "H\n",
      "His\n",
      "Histidine\n",
      "I\n",
      "Ile\n",
      "Isoleucine\n",
      "K\n",
      "Lys\n",
      "Lysine\n",
      "L\n",
      "Leu\n",
      "Leucine\n",
      "M\n",
      "Met\n",
      "Methionine\n",
      "N\n",
      "Asn\n",
      "Asparagine\n",
      "P\n",
      "Pro\n",
      "Proline\n",
      "Q\n",
      "Gln\n",
      "Glutamine\n",
      "R\n",
      "Arg\n",
      "Arginine\n",
      "S\n",
      "Ser\n",
      "Serine\n",
      "T\n",
      "Thr\n",
      "Threonine\n",
      "V\n",
      "Val\n",
      "Valine\n",
      "W\n",
      "Trp\n",
      "Tryptophan\n",
      "Y\n",
      "Tyr\n",
      "Tyrosine\n"
     ]
    }
   ],
   "source": [
    "## We can iterate through this table to get the data\n",
    "for row in amino[0]:\n",
    "    for cell in row:\n",
    "        print(cell.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the column headers are missing above. This is because that text is not directly within the table cells, it is actually nested within a `<font>` tag, which allows additional formatting of the text. The code below will solve this problem. The Xpath `text()` function will extract text, and using the `//` means that it will find text anywere under the `<td>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IUPAC amino acid code\n",
      "Three letter code\n",
      "Amino acid\n",
      "A\n",
      "Ala\n",
      "Alanine\n",
      "C\n",
      "Cys\n",
      "Cysteine\n",
      "D\n",
      "Asp\n",
      "Aspartic Acid\n",
      "E\n",
      "Glu\n",
      "Glutamic Acid\n",
      "F\n",
      "Phe\n",
      "Phenylalanine\n",
      "G\n",
      "Gly\n",
      "Glycine\n",
      "H\n",
      "His\n",
      "Histidine\n",
      "I\n",
      "Ile\n",
      "Isoleucine\n",
      "K\n",
      "Lys\n",
      "Lysine\n",
      "L\n",
      "Leu\n",
      "Leucine\n",
      "M\n",
      "Met\n",
      "Methionine\n",
      "N\n",
      "Asn\n",
      "Asparagine\n",
      "P\n",
      "Pro\n",
      "Proline\n",
      "Q\n",
      "Gln\n",
      "Glutamine\n",
      "R\n",
      "Arg\n",
      "Arginine\n",
      "S\n",
      "Ser\n",
      "Serine\n",
      "T\n",
      "Thr\n",
      "Threonine\n",
      "V\n",
      "Val\n",
      "Valine\n",
      "W\n",
      "Trp\n",
      "Tryptophan\n",
      "Y\n",
      "Tyr\n",
      "Tyrosine\n"
     ]
    }
   ],
   "source": [
    "for i in tree.xpath(\"//table[@cols='3']/tr/td//text()\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start using for loops to write more interesting queries, and convert the entire table to a data structure  we can more easily use.\n",
    "\n",
    "One thing to keep in mind is that once you have focused on a particular part of the tree, your position is defined relative to that element. However, the object still contains the full information about the whole HTML document's tree. You are able to start a query with the absolute path of the full tree with `/` or you are able to use `.` in order to define a query relative to your current position. Here we use the `.` operator to define a path relative to the current element (e.g. the table element stored in `amino[0]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['IUPAC amino acid code', 'Three letter code', 'Amino acid'],\n",
       " ['A', 'Ala', 'Alanine'],\n",
       " ['C', 'Cys', 'Cysteine'],\n",
       " ['D', 'Asp', 'Aspartic Acid'],\n",
       " ['E', 'Glu', 'Glutamic Acid'],\n",
       " ['F', 'Phe', 'Phenylalanine'],\n",
       " ['G', 'Gly', 'Glycine'],\n",
       " ['H', 'His', 'Histidine'],\n",
       " ['I', 'Ile', 'Isoleucine'],\n",
       " ['K', 'Lys', 'Lysine'],\n",
       " ['L', 'Leu', 'Leucine'],\n",
       " ['M', 'Met', 'Methionine'],\n",
       " ['N', 'Asn', 'Asparagine'],\n",
       " ['P', 'Pro', 'Proline'],\n",
       " ['Q', 'Gln', 'Glutamine'],\n",
       " ['R', 'Arg', 'Arginine'],\n",
       " ['S', 'Ser', 'Serine'],\n",
       " ['T', 'Thr', 'Threonine'],\n",
       " ['V', 'Val', 'Valine'],\n",
       " ['W', 'Trp', 'Tryptophan'],\n",
       " ['Y', 'Tyr', 'Tyrosine']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remember here we are only interested in the amino acid table\n",
    "## Use the . to ensure you are searching for rows within that table only\n",
    "table_list = []\n",
    "for tr in amino[0].xpath('./tr'):\n",
    "    table_list.append(tr.xpath('./td//text()'))\n",
    "table_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup \n",
    "\n",
    "While that was certainly a fun demonstration of how HTML is organized and can be digested for further analysis, manual XPath evaluations can be a tedious process. Beautiful Soup is a package meant to make the process of getting information from web documents much simpler.\n",
    "\n",
    "In Beautiful Soup, we first import the package in order to create a \"soup\" object. Here we use the html object that we acquired earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can perform all sorts of different manipulations on the data, and Beautiful Soup takes care of the many of the details behind the scenes. Let's just take a look a couple quick examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<table border=\"\" cellpadding=\"2\" cellspacing=\"0\" cols=\"2\" width=\"350\">\n",
       " <tr>\n",
       " <td bgcolor=\"#B0C4DE\"><font color=\"#000000\">IUPAC nucleotide code</font></td>\n",
       " <td bgcolor=\"#B0C4DE\"><font color=\"#000000\">Base</font></td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>A</td>\n",
       " <td>Adenine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>C</td>\n",
       " <td>Cytosine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>G</td>\n",
       " <td>Guanine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>T (or U)</td>\n",
       " <td>Thymine (or Uracil)</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>R</td>\n",
       " <td>A or G</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>Y</td>\n",
       " <td>C or T</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>S</td>\n",
       " <td>G or C</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>W</td>\n",
       " <td>A or T</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>K</td>\n",
       " <td>G or T</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>M</td>\n",
       " <td>A or C</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>B</td>\n",
       " <td>C or G or T</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>D</td>\n",
       " <td>A or G or T</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>H</td>\n",
       " <td>A or C or T</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>V</td>\n",
       " <td>A or C or G</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>N</td>\n",
       " <td>any base</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>. or -</td>\n",
       " <td>gap</td>\n",
       " </tr>\n",
       " </table>,\n",
       " <table border=\"\" cellpadding=\"2\" cellspacing=\"0\" cols=\"3\" width=\"350\">\n",
       " <tr>\n",
       " <td bgcolor=\"#B0C4DE\"><font color=\"#000000\">IUPAC amino acid code</font></td>\n",
       " <td bgcolor=\"#B0C4DE\"><font color=\"#000000\">Three letter code</font></td>\n",
       " <td bgcolor=\"#B0C4DE\"><font color=\"#000000\">Amino acid</font></td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>A</td>\n",
       " <td>Ala</td>\n",
       " <td>Alanine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>C</td>\n",
       " <td>Cys</td>\n",
       " <td>Cysteine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>D</td>\n",
       " <td>Asp</td>\n",
       " <td>Aspartic Acid</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>E</td>\n",
       " <td>Glu</td>\n",
       " <td>Glutamic Acid</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>F</td>\n",
       " <td>Phe</td>\n",
       " <td>Phenylalanine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>G</td>\n",
       " <td>Gly</td>\n",
       " <td>Glycine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>H</td>\n",
       " <td>His</td>\n",
       " <td>Histidine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>I</td>\n",
       " <td>Ile</td>\n",
       " <td>Isoleucine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>K</td>\n",
       " <td>Lys</td>\n",
       " <td>Lysine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>L</td>\n",
       " <td>Leu</td>\n",
       " <td>Leucine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>M</td>\n",
       " <td>Met</td>\n",
       " <td>Methionine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>N</td>\n",
       " <td>Asn</td>\n",
       " <td>Asparagine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>P</td>\n",
       " <td>Pro</td>\n",
       " <td>Proline</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>Q</td>\n",
       " <td>Gln</td>\n",
       " <td>Glutamine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>R</td>\n",
       " <td>Arg</td>\n",
       " <td>Arginine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>S</td>\n",
       " <td>Ser</td>\n",
       " <td>Serine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>T</td>\n",
       " <td>Thr</td>\n",
       " <td>Threonine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>V</td>\n",
       " <td>Val</td>\n",
       " <td>Valine</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>W</td>\n",
       " <td>Trp</td>\n",
       " <td>Tryptophan</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>Y</td>\n",
       " <td>Tyr</td>\n",
       " <td>Tyrosine</td>\n",
       " </tr>\n",
       " </table>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find all tables in the document\n",
    "tables = soup.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table border=\"\" cellpadding=\"2\" cellspacing=\"0\" cols=\"3\" width=\"350\">\n",
       "<tr>\n",
       "<td bgcolor=\"#B0C4DE\"><font color=\"#000000\">IUPAC amino acid code</font></td>\n",
       "<td bgcolor=\"#B0C4DE\"><font color=\"#000000\">Three letter code</font></td>\n",
       "<td bgcolor=\"#B0C4DE\"><font color=\"#000000\">Amino acid</font></td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>A</td>\n",
       "<td>Ala</td>\n",
       "<td>Alanine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>C</td>\n",
       "<td>Cys</td>\n",
       "<td>Cysteine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>D</td>\n",
       "<td>Asp</td>\n",
       "<td>Aspartic Acid</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>E</td>\n",
       "<td>Glu</td>\n",
       "<td>Glutamic Acid</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>F</td>\n",
       "<td>Phe</td>\n",
       "<td>Phenylalanine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>G</td>\n",
       "<td>Gly</td>\n",
       "<td>Glycine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>H</td>\n",
       "<td>His</td>\n",
       "<td>Histidine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>I</td>\n",
       "<td>Ile</td>\n",
       "<td>Isoleucine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>K</td>\n",
       "<td>Lys</td>\n",
       "<td>Lysine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>L</td>\n",
       "<td>Leu</td>\n",
       "<td>Leucine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>M</td>\n",
       "<td>Met</td>\n",
       "<td>Methionine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>N</td>\n",
       "<td>Asn</td>\n",
       "<td>Asparagine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>P</td>\n",
       "<td>Pro</td>\n",
       "<td>Proline</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>Q</td>\n",
       "<td>Gln</td>\n",
       "<td>Glutamine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>R</td>\n",
       "<td>Arg</td>\n",
       "<td>Arginine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>S</td>\n",
       "<td>Ser</td>\n",
       "<td>Serine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>T</td>\n",
       "<td>Thr</td>\n",
       "<td>Threonine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>V</td>\n",
       "<td>Val</td>\n",
       "<td>Valine</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>W</td>\n",
       "<td>Trp</td>\n",
       "<td>Tryptophan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>Y</td>\n",
       "<td>Tyr</td>\n",
       "<td>Tyrosine</td>\n",
       "</tr>\n",
       "</table>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find the first table that matches some criteria\n",
    "table = soup.find(\"table\",{\"width\":\"350\",\"cols\":\"3\"})\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['IUPAC amino acid code', 'Three letter code', 'Amino acid'],\n",
       " ['A', 'Ala', 'Alanine'],\n",
       " ['C', 'Cys', 'Cysteine'],\n",
       " ['D', 'Asp', 'Aspartic Acid'],\n",
       " ['E', 'Glu', 'Glutamic Acid'],\n",
       " ['F', 'Phe', 'Phenylalanine'],\n",
       " ['G', 'Gly', 'Glycine'],\n",
       " ['H', 'His', 'Histidine'],\n",
       " ['I', 'Ile', 'Isoleucine'],\n",
       " ['K', 'Lys', 'Lysine'],\n",
       " ['L', 'Leu', 'Leucine'],\n",
       " ['M', 'Met', 'Methionine'],\n",
       " ['N', 'Asn', 'Asparagine'],\n",
       " ['P', 'Pro', 'Proline'],\n",
       " ['Q', 'Gln', 'Glutamine'],\n",
       " ['R', 'Arg', 'Arginine'],\n",
       " ['S', 'Ser', 'Serine'],\n",
       " ['T', 'Thr', 'Threonine'],\n",
       " ['V', 'Val', 'Valine'],\n",
       " ['W', 'Trp', 'Tryptophan'],\n",
       " ['Y', 'Tyr', 'Tyrosine']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Iterate through the table and create a list of lists\n",
    "table_list2 = []\n",
    "for row in table.find_all(\"tr\"):\n",
    "    cells = row.find_all(\"td\")\n",
    "    newCells = []\n",
    "    for c in cells:\n",
    "        newCells.append(c.get_text())\n",
    "    table_list2.append(newCells)\n",
    "table_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Developer's Console\n",
    "\n",
    "Both Chrome and Firefox are equipped with a developer's console, meant for debugging code while writing websites. This console can also be used to see what elements your computer is interfacing with while you surf the web. \n",
    "\n",
    "To open the developer's console in firefox, press Ctrl+Shift+K in Windows or Cmd+Opt+K in OSX. The network tab will allow you to see what information is being sent when, while the Inspector tab allows you to hover over code and see what element of the page it represents. \n",
    "\n",
    "Chrome's developer console can be accessed with Ctrl+Shift+J on Windows or Cmd+Opt+J on OSX. While the tabs are named slightly differently, the functions are essentially the same. Notably, Chrome provides native support for web scraping, though the data it gives are usually oriented more toward the organization of entire sites and less toward acquiring data from an individual page.\n",
    "\n",
    "If you plan on getting data from the web, this is an invaluable tool that will save you a lot of time finding out where data is stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Word On APIs And robots.txt\n",
    "\n",
    "Before scraping a site, it is worth taking a couple of things into account in order to make sure that you are a good citizen of the web.  The robots.txt file located in the root directory of most websites will usually give you an idea of which directories are and are not allowed for web scraping. It is good practice if you are scraping a large amount of data to make sure that you adhere to the areas that are described by robots.txt with the \"Allow:\" tag. \n",
    "\n",
    "Many sites also provide an Application Programming Interface (API) that allows you to acquire information directly without scraping web data from the HTML interface, saving both you and the site manager time and money. If an API is available, it is almost always advisable to make use of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Class Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 1.\n",
    "## Extract the title and author list for the \n",
    "## first reference in SHH.xml\n",
    "## Get the XML document's namespace\n",
    "import xml.etree.ElementTree as et\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 2.\n",
    "## Using either lxml or BeautifulSoup, scrape the values from the first \n",
    "## table at the URL below, which contains nucleotides and their corresponding name\n",
    "## Create a dictionary from these values where the nucleotide code is the key.\n",
    "## \"http://www.bioinformatics.org/sms/iupac.html\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <u>Python Essential Reference</u>, David Beazley, 4th Edition, Addison‚ÄêWesley (2008)\n",
    "- <u>Python for Bioinformatics</u>, Sebastian Bassi, CRC Press (2010)\n",
    "- [http://en.wikipedia.org/wiki/XML](http://en.wikipedia.org/wiki/XML)\n",
    "- [http://docs.python.org/](http://docs.python.org/)\n",
    "- [https://docs.python.org/2/library/xml.etree.elementtree.html](https://docs.python.org/2/library/xml.etree.elementtree.html)\n",
    "- [LXML HTML Xpath Tutorial](http://lxml.de/parsing.html)\n",
    "- [BeautifulSoup Documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [XPath Syntax Guide](https://www.w3schools.com/xml/xpath_syntax.asp)\n",
    "\n",
    "#### Last Updated: 22-Sep-2021"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d892f18-197e-4c79-ac0b-8f883e174642",
   "metadata": {},
   "source": [
    "# BMI565: Bioinformatics Programming & Scripting\n",
    "\n",
    "#### (C) Michael Mooney (mooneymi@ohsu.edu)\n",
    "\n",
    "## Week 4: XML, HTML and Web Scraping\n",
    "\n",
    "**Thanks to Ryan Swan for the materials on HTML and web scraping.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e42775-476f-4202-8635-18be5629923c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# XML Overview\n",
    "\n",
    "><b>XML</b> stands for E<u>x</u>tensible <u>M</u>arkup <u>L</u>anguage, and is a set of rules for encoding documents in a machine-readable format. In bioinformatics, XML is a commonly used format for sharing heterogenous data (as opposed to delimited files, where every record (row) contains the same data elements).\n",
    "\n",
    "The World Wide Web Consortium (W3C) oversaw XML development in 1996.\n",
    "\n",
    "### XML Design Goals:\n",
    "1. XML shall be straightforwardly usable over the Internet\n",
    "2. XML shall support a wide variety of applications\n",
    "3. XML shall be compatible with Standard Generalized Markup Language (SGML)\n",
    "4. It shall be easy to write programs that process XML documents\n",
    "5. The number of optional features in XML is to be kept to the absolute minimum\n",
    "6. XML documents should be human-legible and reasonably clear\n",
    "7. The XML design should be prepared quickly\n",
    "8. The design of XML shall be formal and concise\n",
    "9. XML documents shall be easy to create\n",
    "10. Terseness in XML markup is of minimal importance\n",
    "\n",
    "### Why can't we use CSV formats?\n",
    "\n",
    "We usually can, but...\n",
    "\n",
    "1. CSV files are not always human readable (other documentation is often necessary to identify data elements)\n",
    "2. Inconsistencies are more likely \n",
    "3. CSV files don't easily support multiple levels of data\n",
    "4. CSV files don't easily support addition details such as formatting or meta data (experimental protocols, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a0e2ac-2964-46bd-b5d6-abb99b44128b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XML Format\n",
    "\n",
    "The first couple lines of an XML document contain information about the XML version used, the document structure and comments:\n",
    "\n",
    "#### Version\n",
    "\n",
    "```xml\n",
    "<?xml version='1.0' encoding='UTF-8'?>\n",
    "```\n",
    "    \n",
    "#### Document Type Declaration\n",
    "```xml\n",
    "<uniprot xmlns=\"http://uniprot.org/uniprot\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://uniprot.org/uniprot http://www.uniprot.org/support/docs/uniprot.xsd\">\n",
    "```\n",
    "\n",
    "#### XML Document Body\n",
    "\n",
    "The body of an XML document contains labeled data elements. Data elements can be nested to show relationships. Data labels are called \"tags\", which can also contain attributes (values are always strings) that provide additional information about the data.\n",
    "    \n",
    "```xml\n",
    "    <parent_tag>\n",
    "        <child_tag attribute1=\"value1\" attrubute2=\"value2\">data</child_tag>\n",
    "    </parent_tag>\n",
    "```\n",
    "\n",
    "It is subjective whether to provide additional information as attributes or additional data elements:\n",
    "\n",
    "```xml\n",
    "    <contact birthdate=\"1-1-1980\">\n",
    "        <name>John Smith</name>\n",
    "    </contact>\n",
    "    \n",
    "    <contact>\n",
    "        <name>John Smith</name>\n",
    "        <birthdate>1-1-1980</birthdate>\n",
    "    </contact>\n",
    "```\n",
    "\n",
    "<center><img src=\"./images/xml_graph.png\"></center>\n",
    "\n",
    "#### DTD and XML Schema\n",
    "\n",
    "- Document Type Definitions (DTD) and XML Schemas are two ways of describing the structure and content of an XML document\n",
    "- XML Schemas (a.k.a. XML Schema Definitions or XSDs) were designed to improve upon the shortcomings of DTDs\n",
    "    - data type support\n",
    "    - namespace aware\n",
    "- Example: the UniProt XSD - [http://www.uniprot.org/support/docs/uniprot.xsd](http://www.uniprot.org/support/docs/uniprot.xsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706c832-08ce-4e92-bc9d-23f55b864303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "company_xmlpath = os.path.join('data', 'company.xml')\n",
    "\n",
    "company_xmlstring = ('''<?xml version='1.0' ?>\n",
    "                        <company>\n",
    "                            <department>\n",
    "                                <employee>\n",
    "                                    <name>John Doe</name>\n",
    "                                    <job>Software Analyst</job>\n",
    "                                    <salary>2000</salary>\n",
    "                                </employee>\n",
    "                                <employee>\n",
    "                                    <name>Jane Fletcher</name>\n",
    "                                    <job>Designer</job>\n",
    "                                    <salary>2500</salary>\n",
    "                                </employee>        \n",
    "                                <employee>\n",
    "                                    <name>Mike Mooney</name>\n",
    "                                    <job>Professor</job>\n",
    "                                    <salary>250000</salary>\n",
    "                                </employee>\n",
    "                                <employee>\n",
    "                                    <name>Gareth Harman</name>\n",
    "                                    <job>Student</job>\n",
    "                                    <salary>10</salary>\n",
    "                                </employee>\n",
    "                            </department>\n",
    "                        </company>''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0fbb14-b046-4a10-9c3a-866d4232eb6b",
   "metadata": {},
   "source": [
    "# LXML\n",
    "\n",
    "It uses a querying syntax called XML Path Language (XPath) to parse the tree structure and return relevent information from the document.\n",
    "\n",
    "`parse()`\n",
    "> Read an xml file\n",
    "> Returns a `ElementTree` object\n",
    "\n",
    "`fromstring()`\n",
    "> Create an `Element` object from a string-like XML\n",
    "\n",
    "It's important to note that loading each method of reading above create different objects which we can see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1320189-22e4-4bad-b4ea-22ecddc515a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lxml.etree as et\n",
    "import re\n",
    "\n",
    "# Lets load our object from our string object above\n",
    "parse_company = et.fromstring(company_xmlstring)\n",
    "tree_company = parse_company.getroottree()\n",
    "\n",
    "print(f'parse_company: {type(parse_company)}')\n",
    "print(f'tree_company: {type(tree_company)}')\n",
    "\n",
    "# And load from an xml file directly\n",
    "tree_company = et.parse(company_xmlpath)\n",
    "\n",
    "print(f'tree_company: {type(tree_company)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b2cc3-9a1b-4d39-baf4-5457dbf2a66f",
   "metadata": {},
   "source": [
    "> Lets look at the root node and some of the information about our xml included an given elements `tag` and `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e8a75b-ee7c-41e5-9976-086e36bbf696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtain the root of our node\n",
    "root_company = tree_company.getroot()\n",
    "print(f'root_company: {type(root_company)}')\n",
    "\n",
    "print(f'Company: {root_company.tag} Len: {len(root_company)}')\n",
    "print(f'Company: {root_company[0].tag} Len: {len(root_company[0])}')\n",
    "print(f'Company: {root_company[0][0].tag} Len: {len(root_company[0][0])}')\n",
    "\n",
    "print(f'{root_company[0][0][0].tag}')\n",
    "print(f'{root_company[0][0][0].text}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a803cc89-e209-4e17-a5a3-79e84872e4b7",
   "metadata": {},
   "source": [
    "### Walking the tree\n",
    "\n",
    "`iterwalk()`\n",
    "> Iteratively *walk* the elements of an `ElementTree` or `Element` object\n",
    "\n",
    "`iterparse()`\n",
    "> Iteratively *parse* and walk the elements of an .xml file\n",
    "\n",
    "`element.clear()`\n",
    "> This statement is important!\n",
    "\n",
    "> Oftentimes we are traversing a very large .xml file (sometimes >4GB), sometimes we might only have 4GB of ram total, so if we want to traverse the xmltree we need to clear objects from memory as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31f40fe-0387-4ecb-b2dc-9221e023008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def walk(iter_obj):\n",
    "    \n",
    "    ''' Walking an ElementTree Object '''\n",
    "\n",
    "    event, root = next(iter_obj)            # Create our generator\n",
    "   \n",
    "    for event, element in iter_obj:         # Walk through the elements\n",
    "        if (event == 'end' and              # Check it is the end of the object\n",
    "            element.tag != root.tag and     # Check it isnt our root object\n",
    "            element.text is not None):      # Check it isnt None\n",
    "            if element.text.strip() != '':  # Check that the attribute has text\n",
    "                print(f'{element.tag}:{element.text.strip()}')\n",
    "                element.clear()             # Clear this element from memory\n",
    "    root.clear()                            # Clear the root from memory\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d40bde-f4a5-49c3-a54b-546db6a8d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our generator for our parser\n",
    "iter_et_fromfile = et.iterparse(company_xmlpath, events=['start', 'end'])\n",
    "\n",
    "# These will do the same thing in different ways\n",
    "walk(iter_et_fromfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e54ca5-1515-4046-bf04-331fc3756776",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_et_fromtree = et.iterwalk(root_company, events=['start', 'end'])\n",
    "walk(iter_et_fromtree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df31cd-d09a-44be-b9f2-b16365fc44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tree_company = et.parse(company_xmlpath)\n",
    "root_company = tree_company.getroot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060523de-9860-4668-b806-62df86e32f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6ce02ac-7a19-4bf9-ab03-bbef2061ca15",
   "metadata": {},
   "source": [
    "## Namespaces\n",
    "\n",
    "> Namespaces allow us to avoid name conflicts by using `prefixes`\n",
    "\n",
    "```xml\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>Column1</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "    <width>10</width>\n",
    "</table>\n",
    "```\n",
    "\n",
    "Combining these objects would lead to conflicts due to the differing meaning of the variable `<table>`\n",
    "\n",
    "To solve, we can add namespaces usually given in the format\n",
    "\n",
    "```xml \n",
    "<x:table xmlns:h=\"http://www.w3.org/TR/html4/\">\n",
    "```\n",
    "\n",
    "Thus, one solution to our previous issues could look as following,\n",
    "\n",
    "```xml\n",
    "<h:table xmlns:h=\"http://www.w3.org/TR/html4/\">\n",
    "    <h:tr>\n",
    "        <h:td>Column1</h:td>\n",
    "    </h:tr>\n",
    "</h:table>\n",
    "\n",
    "<f:table xmlns:f=\"https://www.w3schools.com/furniture\">\n",
    "    <f:width>10</f:width>\n",
    "</f:table>\n",
    "```\n",
    "\n",
    "#### Extracting namespaces\n",
    "\n",
    "We can obtain a documents namespace using the following syntax\n",
    "\n",
    "```python\n",
    "furniture_tree = et.parse(path_to_furniture_xml)\n",
    "namespace = re.match(r\"{.*}\", furniture_tree.tag).group()\n",
    "namespace\n",
    "```\n",
    "\n",
    "Note:\n",
    "\n",
    "> Often times we see our variable point to a URL, it isn't used to parse or reference any information from the URL but usually points to a page containing additional information about the XML's namespace\n",
    "\n",
    "References:\n",
    "- https://www.w3schools.com/xml/xml_namespaces.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be70dbbd-4e67-4c6c-905e-60511a0d08f0",
   "metadata": {},
   "source": [
    "# Searching for Elements and XPath Queries\n",
    "\n",
    "\n",
    "- Stands for XML Path Language\n",
    "- Uses \"path like\" syntax to identify and navigate nodes in an XML document\n",
    "- Contains over 200 built-in functions\n",
    "- A major element in the XSLT standard\n",
    "- A W3C recommendation\n",
    "\n",
    "Reference:\n",
    "- [W3 XPath](https://www.w3schools.com/xml/xpath_intro.asp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b179f-ae18-4d1d-9289-ae37a65984ff",
   "metadata": {},
   "source": [
    "\n",
    "### XPath Syntax\n",
    "\n",
    "```xml\n",
    "<?xml version='1.0' ?>\n",
    "<company>\n",
    "    <employee id=\"111\">\n",
    "        <name>John Doe</name>\n",
    "        <job>Software Analyst</job>\n",
    "        <salary>2000</salary>\n",
    "    </employee>\n",
    "    <employee id=\"222\">\n",
    "        <name>Jane Fletcher</name>\n",
    "        <job>Designer</job>\n",
    "        <salary>2500</salary>\n",
    "    </employee>       \n",
    "    <employee>\n",
    "        <name>Steven Smith</name>\n",
    "        <job>Cantelope Eater</job>\n",
    "        <salary>25000</salary>\n",
    "    </employee>  \n",
    "</company>\n",
    "```\n",
    "\n",
    "| Expression   | Description                                           |\n",
    "|--------------|-------------------------------------------------------|\n",
    "| `nodename`   | Get nodes with name \"nodename\"                        |\n",
    "| `/`          | Get nodes from the root node                          |\n",
    "| `//`         | Get nodes **FROM THE ENTIRE DOCUMENT** wherever they are |\n",
    "| `.`          | Get the current node                                  |\n",
    "| `..`         | Get the parent of the current node                    |\n",
    "| `@`          | Get an attribute                                      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818dff5-bffd-4024-8e6a-7d65d6a646c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reload the xml\n",
    "tree_company = et.parse(os.path.join('data', 'company_sml.xml'))\n",
    "root_company = tree_company.getroot()\n",
    "\n",
    "# Get all employee nodes that are a child of our specified element\n",
    "print(tree_company.xpath('employee'))\n",
    "\n",
    "# Get the root element\n",
    "print(tree_company.xpath('/company'))\n",
    "\n",
    "# Get name elements that are children of an employee element\n",
    "print(tree_company.xpath('employee/name'))\n",
    "\n",
    "# Get the current node\n",
    "print(tree_company.xpath('.'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0bab61-7b59-4a08-bf1d-160d5abbcf37",
   "metadata": {},
   "source": [
    "### Predicates\n",
    "\n",
    "- Denoted by `[ ]` square brackets\n",
    "- Allow us to identify nodes that contain specific values\n",
    "\n",
    "| Expression             | Description                                                     |\n",
    "|------------------------|-----------------------------------------------------------------|\n",
    "| `/node[n]`             | Get the n'th item                                               |\n",
    "| `/node[last()]`        | Get the last element                                            |\n",
    "| `/node[last()-1]`      | Get second to last element                                      |\n",
    "| `//node[@attr]`        | Get elements that have an attribute named \"attr\"                |\n",
    "| `//node[@attr=\"what\"]` | Get elements that have an attribute named \"attr\" that is \"what\" |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9500de-839b-4cf2-bf40-7368fc1c364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the first employee element\n",
    "print(tree_company.xpath('employee[1]'))\n",
    "\n",
    "# Get the second to last employee element\n",
    "print(tree_company.xpath('employee[last()-1]'))\n",
    "\n",
    "# Get the employee element that has the \"id\" attribute \n",
    "print(tree_company.xpath('//employee[@id]'))\n",
    "\n",
    "# Get the employee element that has the \"id\" attribute \"222\"\n",
    "print(tree_company.xpath('//employee[@id=\"222\"]'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9560e83b-fced-4601-871a-c967fded6136",
   "metadata": {},
   "source": [
    "### Wildcards\n",
    "\n",
    "> Wildcards allow us to do partial searches for nodes or attributes in our document\n",
    "\n",
    "| Expression   | Description                                    |\n",
    "|--------------|------------------------------------------------|\n",
    "| `*`          | Match any element node                         |\n",
    "| `@*`         | Match any attribute node                       |\n",
    "| `node()`     | Match any node of any kind                     |\n",
    "| `/node/*`    | Get all child elements of \"node\"               |\n",
    "| `//*`        | Get all elements in the document               |\n",
    "| `//node[@*]` | Get all node elements which have any attribute |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e09ff-4962-4a40-99be-1ee57ee163da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Wildcards\n",
    "\n",
    "# Get any child elements of the company node\n",
    "print(tree_company.xpath('/company/*'))\n",
    "\n",
    "# Get any attributes of the first employee element\n",
    "print(tree_company.xpath('employee[1]/@*'))\n",
    "\n",
    "# Get all elements in the document\n",
    "for ii in tree_company.xpath('//*'):\n",
    "    print(ii)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cdf9d5-a47d-4401-9526-bacf80650ea4",
   "metadata": {},
   "source": [
    "> We can also search for items using the `find` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ec2d2-502a-438d-949c-a4302d0dc8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### FIND ####: Search for name (only on the first level)\n",
    "print(root_company.find(\"name\"))\n",
    "\n",
    "\n",
    "#### FIND ####: Search for name anywhere in the tree (.//)\n",
    "print(root_company.find(\".//name\").text)\n",
    "\n",
    "\n",
    "#### FINDALL #: Find all instance of name anywhere in the tree\n",
    "print(root_company.findall(\".//name\"))\n",
    "\n",
    "\n",
    "#### ITERFIND : Generator to find instances of name anywhere in the tree\n",
    "for jj in root_company.iterfind('.//name'):\n",
    "    print(jj.text)\n",
    "\n",
    "    \n",
    "# Same thing but put it in a list\n",
    "[jj.text for jj in root_company.iterfind('.//name')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6a058-c7b9-41a2-9394-20a110009665",
   "metadata": {},
   "source": [
    "# Building/Writing an XML \n",
    "\n",
    "#### Methods for Writing XML\n",
    "<table align=\"left\">\n",
    "<tr><td style=\"text-align:center\"><b>Method</b></td><td><b>Description</b></td></tr>\n",
    "<tr><td style=\"text-align:center\">`et.Element(tag)`</td><td>Creates an element with the specified tag. Returns an element object.</td></tr>\n",
    "<tr><td style=\"text-align:center\">`et.SubElement(element, tag)`</td><td>Creates a child element under the specified element.</td></tr>\n",
    "<tr><td style=\"text-align:center\">`Element.set(key, value)`</td><td>Sets the attributes of an element.</td></tr>\n",
    "<tr><td style=\"text-align:center\">`et.ElementTree(root)`</td><td>Returns an ElementTree object.</td></tr>\n",
    "<tr><td style=\"text-align:center\">`ElementTree.write(file)`</td><td>Writes an ElementTree object to a file.</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48dc6e-6424-4854-a0fe-8fa5b419fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup the root node\n",
    "multnomah_library = et.Element('library')\n",
    "doc = et.ElementTree(multnomah_library)\n",
    "\n",
    "#-> Setup the portland branch\n",
    "portland_branch = et.SubElement(multnomah_library, \"portland_branch\",\n",
    "                                zipcode=\"97239\")\n",
    "\n",
    "#->-> Add our book category\n",
    "horror_books = et.SubElement(portland_branch, \"horror\")\n",
    "\n",
    "#->->-> Add the first book\n",
    "h_book1 = et.SubElement(horror_books, \"book\")\n",
    "\n",
    "#->->->-> Add the elements to our book\n",
    "auth = et.SubElement(h_book1, \"author\", text=\"Scott Smith\")\n",
    "title = et.SubElement(h_book1, \"title\", text=\"The Ruins\")\n",
    "isbn = et.SubElement(h_book1, \"ISBN\", text=\"0307390276\")\n",
    "pub = et.SubElement(h_book1, \"Publisher\", text=\"Vintage\")\n",
    "\n",
    "'''\n",
    "Can also set tags this way\n",
    "\n",
    "pub.tag = \"Publisher\"\n",
    "pub.text = \"Vintage\"\n",
    "'''\n",
    "\n",
    "# Save to XML file\n",
    "with open(os.path.join('data', 'output.xml'), 'wb') as f:\n",
    "    doc.write(f, pretty_print=True, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6766037b-8604-4bd6-a3cd-962b5a66093e",
   "metadata": {},
   "source": [
    "## xmltodict\n",
    "\n",
    "- Another option we have for creating python objects from an xml is `xmltodict`\n",
    "- This tool allows us to open an xml and convert it to a nested python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f53b8-effd-43ea-9ed3-77a4b1cc46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xmltodict\n",
    "\n",
    "with open(os.path.join('data', 'output.xml')) as fd:\n",
    "    doc_dict = xmltodict.parse(fd.read())\n",
    "\n",
    "# Get the ISBN of the first book\n",
    "print(doc_dict['library']['portland_branch']['horror']['book']['ISBN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4262f9-6be7-4ec6-a1c7-3512b30f2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef10f4-707f-4bee-af55-be86dc7d9828",
   "metadata": {},
   "source": [
    "#### Drawbacks to XML?\n",
    "\n",
    "- More difficult to parse than CSV\n",
    "- Verbose syntax means larger files\n",
    "\n",
    "## XML and Bioinformatics\n",
    "#### SBML (Systems Biology Markup Language)\n",
    "- Used to communicate models of biological processes (cell-signaling pathways, regulatory networks). Models can represent:\n",
    "    - Chemical Equations\n",
    "    - Cellular Components: nucleus, cytoplasm, etc.\n",
    "    - Species: genomes, proteomes, etc.\n",
    "- Supported by many applications: [http://sbml.org/SBML_Software_Guide](http://sbml.org/SBML_Software_Guide)\n",
    "- [http://www.ebi.ac.uk/biomodels-main/](http://www.ebi.ac.uk/biomodels-main/)\n",
    "\n",
    "#### KGML (KEGG Markup Language)\n",
    "- A format for KEGG pathway maps\n",
    "    - [http://www.kegg.jp/kegg/xml/](http://www.kegg.jp/kegg/xml/)\n",
    "    \n",
    "#### PDBML (Protein Databank Markup Language)\n",
    "- Describes 3D protein structure\n",
    "    - relative atomic coordinates\n",
    "    - secondary structure assignment\n",
    "    - atomic connectivity\n",
    "- [http://www.rcsb.org/pdb/home/home.do](http://www.rcsb.org/pdb/home/home.do)\n",
    "- [http://pdbml.pdb.org/](http://pdbml.pdb.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d4f8a2-999b-499c-ac54-04718ff3c4ac",
   "metadata": {},
   "source": [
    "## HTML\n",
    "\n",
    "Hypertext Markup Language (HTML) is the basis for most pages that are served on the internet. HTML is actually very similar to XML (Extensible Markup Language), with the caveat that it also contains presentation semantics, which are attributes that specify how information is meant to be displayed or arranged on a screen. But overall, the nested format is almost exactly like an XML document, and because of that, we can extract information from a standard HTML page exactly the same way we would from an XML document. Below is a simple example of an HTML document:\n",
    "\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Hey look, a webpage!</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>webpage goes here</p>\n",
    "    </body>\n",
    "    </html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a60aed-a1f0-4f5c-b370-2f47276219e3",
   "metadata": {},
   "source": [
    "## LXML package\n",
    "\n",
    "We can also use the LXML package to read HTML pages in the tree structure.\n",
    "\n",
    "Before we get started, it helps to have an idea of some of the ways that HTML arranges documents. Most scrapable HTML data is contained in tables like the one at http://www.bioinformatics.org/sms/iupac.html. HTML tables are arranged in the following format:\n",
    "\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            ...\n",
    "        </tr>\n",
    "        <tr>\n",
    "            ...\n",
    "        </tr>\n",
    "    </table>\n",
    "\n",
    "This general format specifies table rows and table dividers, where each divider is a different column. The data in the table is contained inside each of the nested <td></td> tag pairs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0728d96d-8976-441a-b2af-931f653075fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import requests\n",
    "from io import StringIO # This will help us deal with string inputs\n",
    "\n",
    "## Get the code from the url\n",
    "html = requests.get(\"http://www.bioinformatics.org/sms/iupac.html\").text\n",
    "\n",
    "## Next we have to create a parser that will read the info from the HTML \n",
    "## file and tell it what kind of data it will be receiving\n",
    "parser = etree.HTMLParser()\n",
    "tree = etree.parse(StringIO(html),parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e342333-1cf9-4994-9777-eb402ec11319",
   "metadata": {},
   "source": [
    "We now have the webpage represented as a tree of data. This tree is an iterable object, just like we saw above when working with XML documents. We can do all sorts of things now.\n",
    "\n",
    "For example with can iterate through the tree with a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32698f-2be6-4875-82d2-8855098dcc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: here we are only showing two levels of the tree\n",
    "root = tree.getroot()\n",
    "\n",
    "for e in root:\n",
    "    print(e)\n",
    "    for i in e:\n",
    "        print('\\t' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf3372-051e-4769-95b4-69e2b5f1a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The following function will print the entire tree structure\n",
    "## This function looks in each element node, and if it has \n",
    "## contents it performs the same action on the descendent node\n",
    "## Note that this is an example of recursion - a function \n",
    "## that calls itself.\n",
    "\n",
    "def parseTree(e,t='\\t'):\n",
    "    for i in e:\n",
    "        print(str(t) + str(i))\n",
    "        parseTree(i,t=t + '\\t')\n",
    "\n",
    "parseTree(tree.getroot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591319f5-a8ef-4ccf-a712-e5be5f40838e",
   "metadata": {},
   "source": [
    "The `etree` object has a method called `xpath()`, which allows us to perform queries on the tree structure to identify specific elements within the HTML document. For example, if we want to find all tables within the body of the document we would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c145b43-5718-4d6f-a120-d4a42eb81a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will return a list of table elements\n",
    "tables = tree.xpath('body/table')\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60053409-fc0f-4d1c-90ee-200ac8298c74",
   "metadata": {},
   "source": [
    "We can also use tag attributes to perform more specific queries. For instance, we know that the table containing amino acid codes has three columns. To extract this table we could do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4575899f-40a5-4b44-8795-81be19e7ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will find all tables with three columns\n",
    "## Note: the // means it will look anywhere under the current element (root in this case) \n",
    "## (i.e. the table could be nested within another element)\n",
    "amino = tree.xpath(\"//table[@cols='3']\")\n",
    "amino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ee1e3-ce68-43de-9af3-faaed45c33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can iterate through this table to get the data\n",
    "for row in amino[0]:\n",
    "    for cell in row:\n",
    "        print(cell.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70693252-d6d5-45d6-bbb6-e2b87befb4a8",
   "metadata": {},
   "source": [
    "Note that the column headers are missing above. This is because that text is not directly within the table cells, it is actually nested within a `<font>` tag, which allows additional formatting of the text. The code below will solve this problem. The Xpath `text()` function will extract text, and using the `//` means that it will find text anywere under the `<td>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f078c-aa1d-4a93-a02d-3313d43712db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tree.xpath(\"//table[@cols='3']/tr/td//text()\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311852f6-2fe6-4567-8fef-41b7778877cc",
   "metadata": {},
   "source": [
    "We can now start using for loops to write more interesting queries, and convert the entire table to a data structure  we can more easily use.\n",
    "\n",
    "One thing to keep in mind is that once you have focused on a particular part of the tree, your position is defined relative to that element. However, the object still contains the full information about the whole HTML document's tree. You are able to start a query with the absolute path of the full tree with `/` or you are able to use `.` in order to define a query relative to your current position. Here we use the `.` operator to define a path relative to the current element (e.g. the table element stored in `amino[0]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4f556-5bb6-48df-851a-be0fd8e836df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remember here we are only interested in the amino acid table\n",
    "## Use the . to ensure you are searching for rows within that table only\n",
    "table_list = []\n",
    "for tr in amino[0].xpath('./tr'):\n",
    "    table_list.append(tr.xpath('./td//text()'))\n",
    "table_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70df8cc8-7d9b-4708-9176-abda641a30f0",
   "metadata": {},
   "source": [
    "## Beautiful Soup \n",
    "\n",
    "While that was certainly a fun demonstration of how HTML is organized and can be digested for further analysis, manual XPath evaluations can be a tedious process. Beautiful Soup is a package meant to make the process of getting information from web documents much simpler.\n",
    "\n",
    "In Beautiful Soup, we first import the package in order to create a \"soup\" object. Here we use the html object that we acquired earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f909cd-c362-41b6-985b-afe0cd6f86a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ac324-0a4f-46ce-a162-0df656e9e00e",
   "metadata": {},
   "source": [
    "From here we can perform all sorts of different manipulations on the data, and Beautiful Soup takes care of the many of the details behind the scenes. Let's just take a look a couple quick examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577089c6-bbf0-44ff-8fb7-138b713adcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find all tables in the document\n",
    "tables = soup.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df80bb-fef2-4b3c-b8a0-52e9ffa53d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the first table that matches some criteria\n",
    "table = soup.find(\"table\",{\"width\":\"350\",\"cols\":\"3\"})\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f795eeb-15bb-4428-a4d3-d704078a7668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Iterate through the table and create a list of lists\n",
    "table_list2 = []\n",
    "for row in table.find_all(\"tr\"):\n",
    "    cells = row.find_all(\"td\")\n",
    "    newCells = []\n",
    "    for c in cells:\n",
    "        newCells.append(c.get_text())\n",
    "    table_list2.append(newCells)\n",
    "table_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76ae7f-f3c7-4417-aaa5-3001a7e22346",
   "metadata": {},
   "source": [
    "## The Developer's Console\n",
    "\n",
    "Both Chrome and Firefox are equipped with a developer's console, meant for debugging code while writing websites. This console can also be used to see what elements your computer is interfacing with while you surf the web. \n",
    "\n",
    "To open the developer's console in firefox, press Ctrl+Shift+K in Windows or Cmd+Opt+K in OSX. The network tab will allow you to see what information is being sent when, while the Inspector tab allows you to hover over code and see what element of the page it represents. \n",
    "\n",
    "Chrome's developer console can be accessed with Ctrl+Shift+J on Windows or Cmd+Opt+J on OSX. While the tabs are named slightly differently, the functions are essentially the same. Notably, Chrome provides native support for web scraping, though the data it gives are usually oriented more toward the organization of entire sites and less toward acquiring data from an individual page.\n",
    "\n",
    "If you plan on getting data from the web, this is an invaluable tool that will save you a lot of time finding out where data is stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c7dc68-2415-4802-83f7-fe8da7df0d07",
   "metadata": {},
   "source": [
    "## A Word On APIs And robots.txt\n",
    "\n",
    "Before scraping a site, it is worth taking a couple of things into account in order to make sure that you are a good citizen of the web.  The robots.txt file located in the root directory of most websites will usually give you an idea of which directories are and are not allowed for web scraping. It is good practice if you are scraping a large amount of data to make sure that you adhere to the areas that are described by robots.txt with the \"Allow:\" tag. \n",
    "\n",
    "Many sites also provide an Application Programming Interface (API) that allows you to acquire information directly without scraping web data from the HTML interface, saving both you and the site manager time and money. If an API is available, it is almost always advisable to make use of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426d47c-91d5-4c41-898f-b9c5a4c09663",
   "metadata": {},
   "source": [
    "## In-Class Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71fa9e86-1374-426f-8ea8-62f8d183ab40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{http://uniprot.org/uniprot}\n",
      "Sonic hedgehog protein\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Exercise 1.\n",
    "\n",
    "Using our uniprot.xml document,\n",
    "\n",
    "1. Parse the document\n",
    "2. Get the documents namespace\n",
    "3. Get the fullName of the first entry in our document\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf0c1f-a364-408a-9609-ac774c5558d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 2.\n",
    "## Using either lxml or BeautifulSoup, scrape the values from the first \n",
    "## table at the URL below, which contains nucleotides and their corresponding name\n",
    "## Create a dictionary from these values where the nucleotide code is the key.\n",
    "## \"http://www.bioinformatics.org/sms/iupac.html\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105dc92b-9ba9-44ec-9efc-709158035839",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- <u>Python Essential Reference</u>, David Beazley, 4th Edition, Addison‚ÄêWesley (2008)\n",
    "- <u>Python for Bioinformatics</u>, Sebastian Bassi, CRC Press (2010)\n",
    "- [http://en.wikipedia.org/wiki/XML](http://en.wikipedia.org/wiki/XML)\n",
    "- [http://docs.python.org/](http://docs.python.org/)\n",
    "- [https://docs.python.org/2/library/xml.etree.elementtree.html](https://docs.python.org/2/library/xml.etree.elementtree.html)\n",
    "- [LXML HTML Xpath Tutorial](http://lxml.de/parsing.html)\n",
    "- [BeautifulSoup Documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [XPath Syntax Guide](https://www.w3schools.com/xml/xpath_syntax.asp)\n",
    "\n",
    "#### Last Updated: 03-Oct-2022"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
